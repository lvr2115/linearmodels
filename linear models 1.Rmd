---
title: "linear models 1"
author: "Laura Robles-Torres"
date: "2023-11-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
library(tidyverse)
library(p8105.datasets)

set.seed(1)
```

```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb |> 
  mutate(stars = review_scores_location / 2) |> 
  rename(
    borough = neighbourhood_group,
    neighborhood = neighbourhood) |> 
  filter(borough != "Staten Island") |> 
  select(price, stars, borough, neighborhood, room_type)
```

#Fitting models 

Fitting initial model of price (y - outcome) on rating "stars" (x1) and borough (x2) with this code:

The lm function begins with the formula specification – outcome on the left of the ~ and predictors separated by + on the right. As we’ll see shortly, interactions between variables can be specified using *. You can also specify an intercept-only model (outcome ~ 1), a model with no intercept (outcome ~ 0 + ...), and a model using all available predictors (outcome ~ .).
```{r}
fit = lm(price ~ stars + borough, data = nyc_airbnb)
```

Let's look at the result. Does not give you a dataframe but does provide a object of class lm. Used the bronx as a reference group given categorical variable borough. 

x0 = -70.41
x1 = 31.99
x2 = 40.50
x3 = 90.25
x4 = 13.21

```{r, include=FALSE}
fit
summary(fit)
summary(fit)$coef
coef(fit)
fitted.values(fit)
```
'summary' gives you residual information, coefficient estimates, std errors, and runs t-test for each coefficient, as well as R^2, adjusted R^2, the F-test 
if you add '$coef' it will give you just the info re: to the coefficients.
coef(fit) will give you just the coefficients.

But...none of these are tidy. We use the broom package for that.The broom package has functions for obtaining a quick summary of the model and for cleaning up the coefficient table. 

```{r}
fit |> 
  broom::glance() 

fit |>
  broom::tidy()

```
Both of these functions *produce data frames*, which makes it straightforward to include the results in subsequent steps.

```{r}
fit |> 
  broom::tidy() |> 
  select(term, estimate, p.value) |> 
  mutate(term = str_replace(term, "^borough", "Borough: ")) |> 
  knitr::kable(digits = 3)
```

#Be in control for factors. 

R will treat categorical (factor) covariates appropriately and predictably: indicator variables are created for each non-reference category and included in your model, and the factor level is treated as the reference. As with ggplot, being careful with factors is therefore critical!

This code restructures your reference category for borough and orders room_type, showing the new coefficients and results.

```{r}
nyc_airbnb = 
  nyc_airbnb |> 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type))

fit = lm(price ~ stars + borough, data = nyc_airbnb)

fit |> 
  broom::tidy() |> 
  select(term, estimate, p.value) |> 
  mutate(term = str_replace(term, "^borough", "Borough: ")) |> 
  knitr::kable(digits = 3)
```

#Diagnostics 

Looking at fitted values, residuals, etc. to look at our model and assess. Regression diagnostics can identify issues in model fit, especially related to certain failures in model assumptions (normality, linear relationship, etc.). Examining residuals and fitted values are therefore an important component of any modeling exercise.

The modelr package can be used to add residuals and fitted values to a dataframe. Adds column with a residual value. Plot shows distribution of residuals in each of the boroughs. 

```{r}
modelr::add_residuals(nyc_airbnb, fit) |>
  ggplot(aes(x = borough, y = resid)) + geom_violin() +
  ylim(-500, 1500)
```

This looks to give you a lot of extreme skewdness in the residuals in certain boroughs.

```{r}
nyc_airbnb |> 
  modelr::add_residuals(fit) |> 
  ggplot(aes(x = stars, y = resid)) + geom_point() +
  facet_wrap(.~borough)
```

You can see residuals in price start getting more variability as stars (ratings) increase. 
This example has some obvious issues, most notably the presence of extremely large outliers in price and a generally skewed residual distribution. 

There are a few things we might try to do here – including creating a formal rule for the exclusion of outliers, transforming the price variable (e.g. using a log transformation), or fitting a model that is robust to outliers. Dealing with these issues isn’t really the purpose of this class, though, so we’ll note the issues and move on; shortly we’ll look at using the bootstrap for inference in cases like this, where standard approaches to inference may fail.

(For what it’s worth, I’d probably use a combination of median regression, which is less sensitive to outliers than OLS, and maybe bootstrapping for inference. If that’s not feasible, I’d omit rentals with price over $1000 (< 0.5% of the sample) from the primary analysis and examine these separately. I usually avoid transforming the outcome, because the results model is difficult to interpret.)

#Hypothesis testing

```{r}
fit |> 
  broom::tidy() 
```
Model summaries include results of t-tests for single coefficients, and are the standard way of assessing statistical significance.

What about the significance of 'borough'? 
```{r}
fit_null = lm(price ~ stars, data = nyc_airbnb) #null hypothesis is that borough is unassociated with price so do not include
fit_alt = lm(price ~ stars + borough, data = nyc_airbnb) #alt hyp is that it is associated so do include

anova(fit_null, fit_alt) |> #gives you ANOVA table comparing models
  broom::tidy()
```

Testing multiple coefficients is somewhat more complicated. A useful approach is to use nested models, meaning that the terms in a simple “null” model are a subset of the terms in a more complex “alternative” model. The are formal tests for comparing the null and alternative models, even when several coefficients are added in the alternative model. Tests of this kind are required to assess the significance of a categorical predictor with more than two levels, as in the example below.

```{r}
fit_null = lm(price ~ stars + borough, data = nyc_airbnb)
fit_alt = lm(price ~ stars + borough + room_type, data = nyc_airbnb)

anova(fit_null, fit_alt) |> 
  broom::tidy()
```

Note that this works for nested models only. Comparing non-nested models is a common problem that requires other methods; we’ll see one approach in cross validation.

#Nesting data

Fitting models to datasets NESTED within variables. We will use nest() to create a list column that contains datasets and fit separate models ot each one. Not the same as fitting nested models. 

In the airbnb data, we might think that star ratings and room type affects price differently in each borough. One way to allow this kind of effect modification is through interaction terms:

```{r}
nyc_airbnb |> 
  lm(price ~ stars * borough + room_type * borough, data = _) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

This works, but the output takes time to think through – the expected change in price comparing an entire apartment to a private room in Queens, for example, involves the main effect of room type and the Queens / private room interaction.

Alternatively, we can nest *within boroughs* and fit *borough-specific models* associating **price with rating and room type**:

```{r}
nest_lm_res =
  nyc_airbnb |> 
  nest(data = -borough) |> 
  mutate(
    models = map(.x=data,~lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)) |> 
  select(-data, -models) |> 
  unnest(results) |>
  filter(term==)
```

The estimates here are the same as those in the model containing interactions, but are easier to extract from the output.

STRATIFIED ANALYSES: 
Fitting models to nested datasets is a way of performing stratified analyses. These have a tradeoff: stratified models make it easy to interpret covariate effects in each stratum, but don’t provide a mechanism for assessing the significance of differences across strata.

```{r}
nest_lm_res |> 
  select(borough, term, estimate) |> 
  mutate(term = fct_inorder(term)) |> 
  pivot_wider(
    names_from = term, values_from = estimate) |> 
  knitr::kable(digits = 3)
```

Exploratory - we cannot conclude on significance between different boroughs because we have not fit this all into a joint model. We would need to do interaction terms and hypothesis testing to achieve this.


Let's nest more:
An even more extreme example is the assessment of neighborhood effects in Manhattan. The code chunk below fits neighborhood-specific models:

```{r}
manhattan_airbnb =
  nyc_airbnb |> 
  filter(borough == "Manhattan")
#only looking at manhattan observations

#creating nested model of manhattan airbnbs by neighborhood? relates price ot stars and room_type for each of 32 neighborhoods in manhattan

manhattan_nest_lm_res =
  manhattan_airbnb |> 
  nest(data = -neighborhood) |> 
  mutate(
    models = map(.x=data,~lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)) |> 
  select(-data, -models) |> 
  unnest(results)
```

